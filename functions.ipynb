{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "functions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMPTUETHxOBviwwonEXjaDY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinachoir/Convolutional-Neural-Network/blob/main/functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Bd_C61I6QdCC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to unzip file into current working directory\n",
        "\n",
        "import zipfile\n",
        "\n",
        "def unzip_data(filename):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    filename (str) = a filepath to a target zip folder to be unzipped\n",
        "  \"\"\"\n",
        "  zip_file = zipfile.ZipFile(filename, \"r\")\n",
        "  zip_file.extractall()\n",
        "  zip_file.close()"
      ],
      "metadata": {
        "id": "rt2G53Q6ouZk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to explore image classification directory\n",
        "\n",
        "import os\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walk through dir_path returning its contents:\n",
        "    number of subdirectories,\n",
        "    name of each directory,\n",
        "    number of files (images) in each directory\n",
        "  \"\"\"\n",
        "\n",
        "  for dirpath, dirnames, filenames in os.walk(\"dir_path\"):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'\")"
      ],
      "metadata": {
        "id": "dvtAhRmJpjSV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to import an image and resize it to be able to fit in the model\n",
        "\n",
        "def load_prep_image(filename,img_shape=224, scale=True):\n",
        "  \"\"\"\n",
        "  Read an image from filename, turn it into a tensor, and reshape it to (img_shape, img_shape, color_channel)\n",
        "  --\n",
        "  Parameters:\n",
        "  filename (str) : filename of target image\n",
        "  img_shape (int) : size of target image to be resized\n",
        "  scale (boolean) : whether to scale pixal values of image to range(0,1), default=True\n",
        "  \"\"\"\n",
        "  # read image from the target file\n",
        "  img = tf.io.read_file(filename)\n",
        "\n",
        "  # decode image into tensor\n",
        "  img = tf.image.decode_jpeg(img) # color_channels=3 by default in decode_jpeg\n",
        "\n",
        "  # resize the image to the same size as the model has been trained on\n",
        "  img = tf.image.resize(img, size=[img_shape, img_shape])\n",
        "\n",
        "  # rescale the image\n",
        "  if scale:\n",
        "    return img/255.\n",
        "  else:\n",
        "    return img"
      ],
      "metadata": {
        "id": "o6EcI4DnQn0W"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to plot loss and accuracy curves\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_accuracy(history):\n",
        "  \"\"\"\n",
        "  Return loss and accuracy plot separately\n",
        "\n",
        "  Args:\n",
        "    history = tensorflow model history\n",
        "  \"\"\"\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # plot loss\n",
        "  plt.plot(epochs, loss, label='train_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss Curves')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='train_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy Curves')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "nIvEPM0qnKI5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to compare history of the model\n",
        "\n",
        "def compare_historys(original_history, new_history, initial_epochs=5):\n",
        "    \"\"\"\n",
        "    Compares two TensorFlow model History objects.\n",
        "    \n",
        "    Args:\n",
        "      original_history: History object from original model (before new_history)\n",
        "      new_history: History object from continued model training (after original_history)\n",
        "      initial_epochs: Number of epochs in original_history (new_history plot starts from here) \n",
        "    \"\"\"\n",
        "    \n",
        "    # Get original history measurements\n",
        "    acc = original_history.history[\"accuracy\"]\n",
        "    loss = original_history.history[\"loss\"]\n",
        "\n",
        "    val_acc = original_history.history[\"val_accuracy\"]\n",
        "    val_loss = original_history.history[\"val_loss\"]\n",
        "\n",
        "    # Combine original history with new history\n",
        "    total_acc = acc + new_history.history[\"accuracy\"]\n",
        "    total_loss = loss + new_history.history[\"loss\"]\n",
        "\n",
        "    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n",
        "    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n",
        "\n",
        "    # Make plots\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(total_acc, label='Training Accuracy')\n",
        "    plt.plot(total_val_acc, label='Validation Accuracy')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(total_loss, label='Training Loss')\n",
        "    plt.plot(total_val_loss, label='Validation Loss')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "wQbOi8Kvn3_H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create confusion matrix\n",
        "\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def create_confusion_matrix(y_true, y_pred, classes=None, figsize=(10,10), text_size=15, norm=False, savefig=False):\n",
        "  \"\"\"\n",
        "  Create a labelled confusion matrix, comparing prediction and actual labels.\n",
        "\n",
        "  Args:\n",
        "    y_true = array of actual labels\n",
        "    y_pred = array of predicted labels (must be same as y_true in shape)\n",
        "    classes = array of class labels. 'None' : matrix will use integer as labels\n",
        "    figsize = size of confusion matrix figure\n",
        "    text_size = size of figure text (default = 15)\n",
        "    norm = whether to normalize values (default=False)\n",
        "  \n",
        "  Returns\n",
        "    A labelled confusion matrix plot \n",
        "\n",
        "  Example Usage:\n",
        "    create_confusion_matrix(y_true=test_labels,\n",
        "                            y_pred=y_preds,\n",
        "                            classes=class_names,\n",
        "                            figsize=(15,15),\n",
        "                            test_size=12)\n",
        "  \"\"\"\n",
        "  # create confusion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\")/cm.sum(axis=1)[:, np.newaxis] # normalizing\n",
        "  n_classes = cm.shape[0] # number of classes\n",
        "\n",
        "  # plot the figure\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues)\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # are there a list of classes?\n",
        "  if classes:\n",
        "    labels=classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "  \n",
        "  # label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted Label\",\n",
        "         ylabel=\"True Labek\",\n",
        "         xticks=np.arange(n_classes),\n",
        "         yticks=np.arange(n_classes),\n",
        "         xticklabels=labels,\n",
        "         yticklabels=labels)\n",
        "  \n",
        "  # Make x-axis label appears on bottom of figure\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  # Set the threshold for different colors\n",
        "  threshold = (cm.max() + cm.min())/2\n",
        "\n",
        "  # set up the cell text\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    if norm:\n",
        "      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "               horizontalalignment=\"center\",\n",
        "               color=\"white\" if cm[i,j] > threshold else \"navy\",\n",
        "               size=text_size)\n",
        "    \n",
        "    else:\n",
        "      plt.text(j, i, f\"{cm[i, j]}\",\n",
        "               horizontalalignment=\"center\",\n",
        "               color=\"white\" if cm[i,j] > threshold else \"navy\",\n",
        "               size=text_size)\n",
        "  \n",
        "  # save the figure to the current working directory\n",
        "  if savefig:\n",
        "    fig.savefig(\"Confusion_matrix.png\")"
      ],
      "metadata": {
        "id": "_jrYrAFTQnxI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to evaluate model prediction(accuracy, precision, recall, f1-score)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def evaluate_prediction(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "      y_true: true labels in the form of a 1D array\n",
        "      y_pred: predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "\n",
        "  # Calculate model precision, recall and f1 score using \"weighted average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_evaluation = {\"accuracy\": model_accuracy,\n",
        "                      \"precision\": model_precision,\n",
        "                      \"recall\": model_recall,\n",
        "                      \"f1\": model_f1}\n",
        "  return model_evaluation"
      ],
      "metadata": {
        "id": "hPApsq5Eq_q5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to predict images class and plot them (multiclass case)\n",
        "\n",
        "def pred_view(model, filename, class_names):\n",
        "  \"\"\"\n",
        "  Import an image from filename, predict the class name with a trained model\n",
        "  and plot the image with the predicted class name\n",
        "  \"\"\"\n",
        "  # import the image and preprocess it\n",
        "  img = load_prep_image(filename)\n",
        "\n",
        "  # make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # get the predicted class name\n",
        "  if len(pred[0]) > 1: # checking for multiclass classification\n",
        "    pred_class = class_names[pred.argmax()] # the max value is the class\n",
        "  else:\n",
        "    pred_class = class_names[int(tf.round(pred)[0][0])] # for binary classification\n",
        "  \n",
        "  # plot the image and predicted class name\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "KOzEhFikQnuX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create tensorboard callback\n",
        "\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  \"\"\"\n",
        "  Store log files with the filepath:\n",
        "    \"dir_name/experiment_name/current_datetime/\"\n",
        "\n",
        "  Args:\n",
        "    dir_name = target directory to store tensorboard log files\n",
        "    experiment_name = name of experiment directory\n",
        "  \"\"\"\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.Tensorboard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving Tensorboard log files to {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "metadata": {
        "id": "Sj-crxu8Qngg"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}